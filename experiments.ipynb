{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook for running the pipeline\n",
        "\n",
        "## If using Google Colab, mount the drive"
      ],
      "metadata": {
        "id": "4Twk5x81DzUk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qWkHFI1oK4U",
        "outputId": "a3ae0756-c603-4b89-c826-cd2917c5e5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change the directory to where your code is stored"
      ],
      "metadata": {
        "id": "RTCDs4ApD8xt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvz2Zkdpeiso",
        "outputId": "9766d0a8-34ec-4638-a13e-4fbc9fdc4062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1Wvfz1V2cFuXQXlF-xXGPn_dm50NspsYJ/vae-cf-pytorch\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/ADM/Project/vae-cf-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install tensorboardX"
      ],
      "metadata": {
        "id": "we001xfbEEoS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en9vtMQoewIy",
        "outputId": "39fa315e-08d5-4913-a7b2-258fef708223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation:\n",
        "\n",
        "The first step towards running the code, is dataset preparation. Refer to data.py and make the following mentioned changes.\n",
        "\n",
        "1. Change the directory DATA_DIR mentioned on line 116 to the folder where your data is located.\n",
        "2. Uncomment line 138 if you want to keep data with ratings greater than 3.5\n",
        "3. Change the min_uc and min_sc parameters on line 70 as desired. min_uc refers to the users having atleast min_uc number of items in their watch history. min_sc refers to the items used/watched by atleast min_sc users. \n",
        "\n",
        "The data obtained after using data.py on the 2 datasets is present in the pro_sg folder present in the corresponding dataset folders shared above. For ML-20M dataset we had set, min_uc = 5 and min_sc = 4. For Million Songs Dataset, we used min_uc = 20 and min_sc = 200.\n",
        "\n",
        "You need not run dataset.py again for these datasets."
      ],
      "metadata": {
        "id": "SIhIJGZaEJ7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uGVQFD5783t9"
      },
      "outputs": [],
      "source": [
        "# !python data.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the training pipeline\n",
        "\n",
        "Parameters:\n",
        "- cuda: For enabling operations using a GPU\n",
        "- anneal_cap: Cap on the annealing value\n",
        "- total_anneal_steps: Total number of steps on which we divide the anneal_cap\n",
        "- plots: Folder where we store the data obtained after training the model. To get the plots refer to tensorboard documentation. You can use the folder generated in 'runs' folder to get the graphs and analyze data.\n",
        "- lr: Learning rate\n",
        "- epochs: Number of epochs\n",
        "\n",
        "Update 'lossf' variable present on line 212 in models.py for chaging the metric to calculate divergence. By default the value is set to 'KLD' corresponding to KL Divergence. The other options are 'MMD', 'SWD' and 'CWD'.\n",
        "\n",
        "Once, the parameters are set, you can run the code."
      ],
      "metadata": {
        "id": "bogFRgG_FDB6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZqHc2gcPuCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60be83e-8f35-4f2c-dd93-53dacf21a93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "| epoch   1 |  100/ 233 batches | ms/batch 89.59 | loss 574.61\n",
            "| epoch   1 |  200/ 233 batches | ms/batch 96.90 | loss 534.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 32.31s | valid loss 417.04 | n100 0.268 | r20 0.241 | r50 0.354\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |  100/ 233 batches | ms/batch 88.53 | loss 519.77\n",
            "| epoch   2 |  200/ 233 batches | ms/batch 84.16 | loss 504.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 26.83s | valid loss 402.82 | n100 0.307 | r20 0.278 | r50 0.396\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |  100/ 233 batches | ms/batch 89.20 | loss 498.40\n",
            "| epoch   3 |  200/ 233 batches | ms/batch 85.20 | loss 492.69\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 27.09s | valid loss 389.55 | n100 0.351 | r20 0.321 | r50 0.449\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |  100/ 233 batches | ms/batch 87.54 | loss 489.31\n",
            "| epoch   4 |  200/ 233 batches | ms/batch 87.09 | loss 483.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 27.01s | valid loss 384.16 | n100 0.364 | r20 0.338 | r50 0.465\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |  100/ 233 batches | ms/batch 90.28 | loss 481.99\n",
            "| epoch   5 |  200/ 233 batches | ms/batch 84.94 | loss 478.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 27.87s | valid loss 379.92 | n100 0.376 | r20 0.349 | r50 0.475\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |  100/ 233 batches | ms/batch 87.53 | loss 476.95\n",
            "| epoch   6 |  200/ 233 batches | ms/batch 86.42 | loss 472.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 26.97s | valid loss 376.69 | n100 0.384 | r20 0.356 | r50 0.487\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |  100/ 233 batches | ms/batch 88.21 | loss 467.24\n",
            "| epoch   7 |  200/ 233 batches | ms/batch 85.26 | loss 475.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 27.00s | valid loss 374.23 | n100 0.388 | r20 0.361 | r50 0.494\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |  100/ 233 batches | ms/batch 86.95 | loss 474.05\n",
            "| epoch   8 |  200/ 233 batches | ms/batch 86.87 | loss 464.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 27.10s | valid loss 372.24 | n100 0.391 | r20 0.365 | r50 0.498\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |  100/ 233 batches | ms/batch 87.25 | loss 468.31\n",
            "| epoch   9 |  200/ 233 batches | ms/batch 84.96 | loss 466.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 26.91s | valid loss 370.42 | n100 0.393 | r20 0.367 | r50 0.501\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |  100/ 233 batches | ms/batch 84.85 | loss 465.96\n",
            "| epoch  10 |  200/ 233 batches | ms/batch 85.38 | loss 463.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 26.44s | valid loss 368.57 | n100 0.394 | r20 0.370 | r50 0.504\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |  100/ 233 batches | ms/batch 85.59 | loss 465.32\n",
            "| epoch  11 |  200/ 233 batches | ms/batch 83.60 | loss 462.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 26.35s | valid loss 367.23 | n100 0.397 | r20 0.372 | r50 0.507\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |  100/ 233 batches | ms/batch 85.70 | loss 464.59\n",
            "| epoch  12 |  200/ 233 batches | ms/batch 82.29 | loss 457.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 26.19s | valid loss 365.55 | n100 0.397 | r20 0.372 | r50 0.508\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |  100/ 233 batches | ms/batch 84.40 | loss 462.81\n",
            "| epoch  13 |  200/ 233 batches | ms/batch 82.97 | loss 456.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 26.49s | valid loss 364.09 | n100 0.399 | r20 0.373 | r50 0.510\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |  100/ 233 batches | ms/batch 85.30 | loss 456.57\n",
            "| epoch  14 |  200/ 233 batches | ms/batch 82.74 | loss 461.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 26.21s | valid loss 362.97 | n100 0.399 | r20 0.371 | r50 0.510\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |  100/ 233 batches | ms/batch 84.00 | loss 463.91\n",
            "| epoch  15 |  200/ 233 batches | ms/batch 81.53 | loss 451.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 26.03s | valid loss 362.05 | n100 0.399 | r20 0.372 | r50 0.510\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |  100/ 233 batches | ms/batch 83.93 | loss 458.87\n",
            "| epoch  16 |  200/ 233 batches | ms/batch 82.47 | loss 454.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 25.98s | valid loss 360.91 | n100 0.401 | r20 0.374 | r50 0.511\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |  100/ 233 batches | ms/batch 82.84 | loss 459.32\n",
            "| epoch  17 |  200/ 233 batches | ms/batch 83.62 | loss 449.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 26.09s | valid loss 359.78 | n100 0.400 | r20 0.374 | r50 0.511\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |  100/ 233 batches | ms/batch 83.89 | loss 452.09\n",
            "| epoch  18 |  200/ 233 batches | ms/batch 82.35 | loss 454.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 26.07s | valid loss 359.19 | n100 0.401 | r20 0.375 | r50 0.510\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |  100/ 233 batches | ms/batch 82.66 | loss 454.00\n",
            "| epoch  19 |  200/ 233 batches | ms/batch 82.23 | loss 452.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 25.96s | valid loss 358.63 | n100 0.402 | r20 0.375 | r50 0.512\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |  100/ 233 batches | ms/batch 86.03 | loss 453.98\n",
            "| epoch  20 |  200/ 233 batches | ms/batch 82.30 | loss 448.79\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 26.22s | valid loss 357.72 | n100 0.403 | r20 0.376 | r50 0.513\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  21 |  100/ 233 batches | ms/batch 84.48 | loss 452.16\n",
            "| epoch  21 |  200/ 233 batches | ms/batch 82.15 | loss 450.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 26.06s | valid loss 357.24 | n100 0.403 | r20 0.375 | r50 0.513\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |  100/ 233 batches | ms/batch 83.51 | loss 455.56\n",
            "| epoch  22 |  200/ 233 batches | ms/batch 81.78 | loss 447.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 25.86s | valid loss 356.65 | n100 0.404 | r20 0.376 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |  100/ 233 batches | ms/batch 85.08 | loss 451.18\n",
            "| epoch  23 |  200/ 233 batches | ms/batch 81.79 | loss 446.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 26.12s | valid loss 356.05 | n100 0.405 | r20 0.376 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |  100/ 233 batches | ms/batch 84.69 | loss 450.79\n",
            "| epoch  24 |  200/ 233 batches | ms/batch 81.43 | loss 448.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 25.80s | valid loss 355.73 | n100 0.404 | r20 0.375 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |  100/ 233 batches | ms/batch 82.67 | loss 450.63\n",
            "| epoch  25 |  200/ 233 batches | ms/batch 81.93 | loss 444.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 25.82s | valid loss 355.28 | n100 0.403 | r20 0.375 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |  100/ 233 batches | ms/batch 82.65 | loss 448.60\n",
            "| epoch  26 |  200/ 233 batches | ms/batch 81.56 | loss 448.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 25.69s | valid loss 354.95 | n100 0.404 | r20 0.374 | r50 0.512\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |  100/ 233 batches | ms/batch 82.07 | loss 446.59\n",
            "| epoch  27 |  200/ 233 batches | ms/batch 80.98 | loss 446.71\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 25.69s | valid loss 354.65 | n100 0.403 | r20 0.376 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |  100/ 233 batches | ms/batch 82.70 | loss 446.44\n",
            "| epoch  28 |  200/ 233 batches | ms/batch 81.63 | loss 445.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 25.61s | valid loss 354.86 | n100 0.401 | r20 0.372 | r50 0.512\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |  100/ 233 batches | ms/batch 82.27 | loss 448.87\n",
            "| epoch  29 |  200/ 233 batches | ms/batch 81.41 | loss 446.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 25.74s | valid loss 353.91 | n100 0.404 | r20 0.375 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |  100/ 233 batches | ms/batch 82.78 | loss 445.58\n",
            "| epoch  30 |  200/ 233 batches | ms/batch 81.23 | loss 446.38\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 25.67s | valid loss 353.39 | n100 0.405 | r20 0.377 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  31 |  100/ 233 batches | ms/batch 85.69 | loss 443.82\n",
            "| epoch  31 |  200/ 233 batches | ms/batch 81.39 | loss 442.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 26.10s | valid loss 353.43 | n100 0.404 | r20 0.375 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |  100/ 233 batches | ms/batch 82.82 | loss 448.89\n",
            "| epoch  32 |  200/ 233 batches | ms/batch 81.44 | loss 439.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 25.67s | valid loss 353.34 | n100 0.402 | r20 0.374 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |  100/ 233 batches | ms/batch 81.49 | loss 440.06\n",
            "| epoch  33 |  200/ 233 batches | ms/batch 80.84 | loss 450.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 25.49s | valid loss 352.98 | n100 0.404 | r20 0.376 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |  100/ 233 batches | ms/batch 82.15 | loss 441.14\n",
            "| epoch  34 |  200/ 233 batches | ms/batch 80.84 | loss 444.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 25.49s | valid loss 352.86 | n100 0.403 | r20 0.376 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |  100/ 233 batches | ms/batch 80.87 | loss 444.67\n",
            "| epoch  35 |  200/ 233 batches | ms/batch 80.55 | loss 442.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 25.41s | valid loss 352.61 | n100 0.405 | r20 0.375 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |  100/ 233 batches | ms/batch 84.14 | loss 450.68\n",
            "| epoch  36 |  200/ 233 batches | ms/batch 80.32 | loss 437.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 25.65s | valid loss 352.29 | n100 0.404 | r20 0.376 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |  100/ 233 batches | ms/batch 81.14 | loss 442.58\n",
            "| epoch  37 |  200/ 233 batches | ms/batch 81.19 | loss 442.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 25.52s | valid loss 352.10 | n100 0.405 | r20 0.376 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |  100/ 233 batches | ms/batch 83.61 | loss 444.58\n",
            "| epoch  38 |  200/ 233 batches | ms/batch 80.35 | loss 444.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 25.57s | valid loss 351.90 | n100 0.406 | r20 0.378 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |  100/ 233 batches | ms/batch 83.03 | loss 441.93\n",
            "| epoch  39 |  200/ 233 batches | ms/batch 80.53 | loss 443.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 25.54s | valid loss 351.80 | n100 0.406 | r20 0.375 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |  100/ 233 batches | ms/batch 81.75 | loss 446.83\n",
            "| epoch  40 |  200/ 233 batches | ms/batch 79.93 | loss 442.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 25.31s | valid loss 351.70 | n100 0.405 | r20 0.375 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  41 |  100/ 233 batches | ms/batch 81.19 | loss 446.51\n",
            "| epoch  41 |  200/ 233 batches | ms/batch 80.52 | loss 437.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time: 25.33s | valid loss 351.37 | n100 0.406 | r20 0.376 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  42 |  100/ 233 batches | ms/batch 84.70 | loss 450.01\n",
            "| epoch  42 |  200/ 233 batches | ms/batch 80.67 | loss 437.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time: 25.69s | valid loss 351.78 | n100 0.405 | r20 0.375 | r50 0.513\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  43 |  100/ 233 batches | ms/batch 83.62 | loss 447.31\n",
            "| epoch  43 |  200/ 233 batches | ms/batch 80.31 | loss 437.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time: 25.66s | valid loss 351.35 | n100 0.406 | r20 0.375 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  44 |  100/ 233 batches | ms/batch 82.18 | loss 445.17\n",
            "| epoch  44 |  200/ 233 batches | ms/batch 80.35 | loss 439.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time: 25.34s | valid loss 351.88 | n100 0.403 | r20 0.374 | r50 0.512\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  45 |  100/ 233 batches | ms/batch 81.57 | loss 444.75\n",
            "| epoch  45 |  200/ 233 batches | ms/batch 80.39 | loss 441.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time: 25.38s | valid loss 350.73 | n100 0.407 | r20 0.377 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  46 |  100/ 233 batches | ms/batch 84.31 | loss 442.82\n",
            "| epoch  46 |  200/ 233 batches | ms/batch 80.11 | loss 439.19\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time: 25.54s | valid loss 351.03 | n100 0.405 | r20 0.376 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  47 |  100/ 233 batches | ms/batch 81.45 | loss 445.18\n",
            "| epoch  47 |  200/ 233 batches | ms/batch 80.07 | loss 437.03\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time: 25.34s | valid loss 351.23 | n100 0.404 | r20 0.373 | r50 0.514\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  48 |  100/ 233 batches | ms/batch 81.84 | loss 439.77\n",
            "| epoch  48 |  200/ 233 batches | ms/batch 80.24 | loss 439.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time: 25.34s | valid loss 350.73 | n100 0.406 | r20 0.377 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  49 |  100/ 233 batches | ms/batch 81.21 | loss 445.45\n",
            "| epoch  49 |  200/ 233 batches | ms/batch 79.90 | loss 433.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time: 25.38s | valid loss 350.62 | n100 0.406 | r20 0.376 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  50 |  100/ 233 batches | ms/batch 82.09 | loss 440.41\n",
            "| epoch  50 |  200/ 233 batches | ms/batch 79.99 | loss 438.58\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 25.38s | valid loss 351.07 | n100 0.405 | r20 0.376 | r50 0.513\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  51 |  100/ 233 batches | ms/batch 81.56 | loss 442.84\n",
            "| epoch  51 |  200/ 233 batches | ms/batch 79.91 | loss 441.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time: 25.31s | valid loss 350.77 | n100 0.406 | r20 0.377 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  52 |  100/ 233 batches | ms/batch 81.95 | loss 443.95\n",
            "| epoch  52 |  200/ 233 batches | ms/batch 80.32 | loss 439.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time: 25.33s | valid loss 350.95 | n100 0.405 | r20 0.374 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  53 |  100/ 233 batches | ms/batch 81.07 | loss 440.85\n",
            "| epoch  53 |  200/ 233 batches | ms/batch 79.98 | loss 435.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time: 25.25s | valid loss 350.58 | n100 0.407 | r20 0.375 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  54 |  100/ 233 batches | ms/batch 81.67 | loss 440.35\n",
            "| epoch  54 |  200/ 233 batches | ms/batch 80.27 | loss 435.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time: 25.24s | valid loss 350.49 | n100 0.407 | r20 0.376 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  55 |  100/ 233 batches | ms/batch 80.84 | loss 442.90\n",
            "| epoch  55 |  200/ 233 batches | ms/batch 82.03 | loss 435.67\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time: 25.28s | valid loss 350.71 | n100 0.406 | r20 0.376 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  56 |  100/ 233 batches | ms/batch 82.34 | loss 447.46\n",
            "| epoch  56 |  200/ 233 batches | ms/batch 80.13 | loss 429.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time: 25.15s | valid loss 350.36 | n100 0.407 | r20 0.377 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  57 |  100/ 233 batches | ms/batch 81.05 | loss 441.39\n",
            "| epoch  57 |  200/ 233 batches | ms/batch 80.23 | loss 436.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time: 25.06s | valid loss 350.50 | n100 0.407 | r20 0.378 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  58 |  100/ 233 batches | ms/batch 84.18 | loss 441.75\n",
            "| epoch  58 |  200/ 233 batches | ms/batch 80.70 | loss 437.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time: 25.35s | valid loss 350.34 | n100 0.407 | r20 0.378 | r50 0.515\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  59 |  100/ 233 batches | ms/batch 81.01 | loss 443.88\n",
            "| epoch  59 |  200/ 233 batches | ms/batch 80.04 | loss 434.17\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time: 25.04s | valid loss 350.18 | n100 0.407 | r20 0.377 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  60 |  100/ 233 batches | ms/batch 82.36 | loss 441.88\n",
            "| epoch  60 |  200/ 233 batches | ms/batch 79.99 | loss 436.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  60 | time: 25.13s | valid loss 350.33 | n100 0.406 | r20 0.378 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  61 |  100/ 233 batches | ms/batch 80.97 | loss 444.02\n",
            "| epoch  61 |  200/ 233 batches | ms/batch 80.07 | loss 435.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  61 | time: 25.10s | valid loss 350.19 | n100 0.408 | r20 0.377 | r50 0.518\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  62 |  100/ 233 batches | ms/batch 83.57 | loss 443.52\n",
            "| epoch  62 |  200/ 233 batches | ms/batch 80.09 | loss 435.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  62 | time: 25.36s | valid loss 350.20 | n100 0.407 | r20 0.376 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  63 |  100/ 233 batches | ms/batch 80.97 | loss 442.91\n",
            "| epoch  63 |  200/ 233 batches | ms/batch 79.38 | loss 434.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  63 | time: 25.04s | valid loss 350.15 | n100 0.408 | r20 0.379 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  64 |  100/ 233 batches | ms/batch 84.22 | loss 441.91\n",
            "| epoch  64 |  200/ 233 batches | ms/batch 79.86 | loss 438.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  64 | time: 25.36s | valid loss 350.21 | n100 0.407 | r20 0.378 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  65 |  100/ 233 batches | ms/batch 80.77 | loss 438.12\n",
            "| epoch  65 |  200/ 233 batches | ms/batch 80.76 | loss 441.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  65 | time: 25.25s | valid loss 350.21 | n100 0.408 | r20 0.376 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  66 |  100/ 233 batches | ms/batch 83.25 | loss 441.77\n",
            "| epoch  66 |  200/ 233 batches | ms/batch 79.78 | loss 436.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  66 | time: 25.35s | valid loss 350.04 | n100 0.408 | r20 0.378 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  67 |  100/ 233 batches | ms/batch 80.65 | loss 441.11\n",
            "| epoch  67 |  200/ 233 batches | ms/batch 79.87 | loss 434.83\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  67 | time: 25.26s | valid loss 350.45 | n100 0.406 | r20 0.377 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  68 |  100/ 233 batches | ms/batch 82.00 | loss 440.43\n",
            "| epoch  68 |  200/ 233 batches | ms/batch 79.94 | loss 438.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  68 | time: 25.21s | valid loss 350.31 | n100 0.407 | r20 0.378 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  69 |  100/ 233 batches | ms/batch 80.60 | loss 440.64\n",
            "| epoch  69 |  200/ 233 batches | ms/batch 79.73 | loss 438.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  69 | time: 25.18s | valid loss 350.62 | n100 0.407 | r20 0.376 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  70 |  100/ 233 batches | ms/batch 81.56 | loss 445.96\n",
            "| epoch  70 |  200/ 233 batches | ms/batch 80.05 | loss 431.21\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  70 | time: 25.17s | valid loss 350.51 | n100 0.406 | r20 0.377 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  71 |  100/ 233 batches | ms/batch 80.61 | loss 442.57\n",
            "| epoch  71 |  200/ 233 batches | ms/batch 79.81 | loss 433.84\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  71 | time: 25.20s | valid loss 349.78 | n100 0.408 | r20 0.379 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  72 |  100/ 233 batches | ms/batch 81.61 | loss 437.93\n",
            "| epoch  72 |  200/ 233 batches | ms/batch 81.56 | loss 437.76\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  72 | time: 25.45s | valid loss 350.22 | n100 0.408 | r20 0.379 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  73 |  100/ 233 batches | ms/batch 80.44 | loss 437.52\n",
            "| epoch  73 |  200/ 233 batches | ms/batch 79.52 | loss 438.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  73 | time: 25.10s | valid loss 350.67 | n100 0.407 | r20 0.377 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  74 |  100/ 233 batches | ms/batch 81.37 | loss 440.68\n",
            "| epoch  74 |  200/ 233 batches | ms/batch 79.99 | loss 435.98\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  74 | time: 25.13s | valid loss 350.39 | n100 0.407 | r20 0.377 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  75 |  100/ 233 batches | ms/batch 81.04 | loss 444.53\n",
            "| epoch  75 |  200/ 233 batches | ms/batch 79.09 | loss 431.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  75 | time: 25.09s | valid loss 350.49 | n100 0.407 | r20 0.378 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  76 |  100/ 233 batches | ms/batch 81.68 | loss 437.44\n",
            "| epoch  76 |  200/ 233 batches | ms/batch 79.52 | loss 438.91\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  76 | time: 25.14s | valid loss 350.07 | n100 0.409 | r20 0.380 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  77 |  100/ 233 batches | ms/batch 81.66 | loss 437.23\n",
            "| epoch  77 |  200/ 233 batches | ms/batch 80.20 | loss 438.44\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  77 | time: 25.44s | valid loss 349.86 | n100 0.408 | r20 0.378 | r50 0.518\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  78 |  100/ 233 batches | ms/batch 83.34 | loss 439.20\n",
            "| epoch  78 |  200/ 233 batches | ms/batch 81.09 | loss 436.76\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  78 | time: 25.38s | valid loss 350.36 | n100 0.407 | r20 0.378 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  79 |  100/ 233 batches | ms/batch 79.69 | loss 438.79\n",
            "| epoch  79 |  200/ 233 batches | ms/batch 79.40 | loss 435.64\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  79 | time: 25.00s | valid loss 350.02 | n100 0.408 | r20 0.378 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  80 |  100/ 233 batches | ms/batch 81.64 | loss 437.60\n",
            "| epoch  80 |  200/ 233 batches | ms/batch 79.86 | loss 439.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  80 | time: 25.48s | valid loss 350.36 | n100 0.408 | r20 0.379 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  81 |  100/ 233 batches | ms/batch 80.32 | loss 439.54\n",
            "| epoch  81 |  200/ 233 batches | ms/batch 79.45 | loss 437.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  81 | time: 25.09s | valid loss 350.14 | n100 0.408 | r20 0.378 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  82 |  100/ 233 batches | ms/batch 81.24 | loss 435.35\n",
            "| epoch  82 |  200/ 233 batches | ms/batch 79.55 | loss 435.57\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  82 | time: 25.11s | valid loss 350.77 | n100 0.407 | r20 0.376 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  83 |  100/ 233 batches | ms/batch 81.22 | loss 443.55\n",
            "| epoch  83 |  200/ 233 batches | ms/batch 79.83 | loss 432.54\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  83 | time: 25.40s | valid loss 350.22 | n100 0.408 | r20 0.377 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  84 |  100/ 233 batches | ms/batch 82.34 | loss 440.13\n",
            "| epoch  84 |  200/ 233 batches | ms/batch 80.03 | loss 437.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  84 | time: 25.33s | valid loss 350.11 | n100 0.409 | r20 0.380 | r50 0.518\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  85 |  100/ 233 batches | ms/batch 82.56 | loss 441.89\n",
            "| epoch  85 |  200/ 233 batches | ms/batch 79.95 | loss 431.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  85 | time: 25.45s | valid loss 350.58 | n100 0.408 | r20 0.378 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  86 |  100/ 233 batches | ms/batch 84.01 | loss 440.20\n",
            "| epoch  86 |  200/ 233 batches | ms/batch 80.01 | loss 437.50\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  86 | time: 25.46s | valid loss 350.20 | n100 0.409 | r20 0.378 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  87 |  100/ 233 batches | ms/batch 82.25 | loss 439.69\n",
            "| epoch  87 |  200/ 233 batches | ms/batch 79.78 | loss 436.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  87 | time: 25.32s | valid loss 350.92 | n100 0.407 | r20 0.377 | r50 0.516\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  88 |  100/ 233 batches | ms/batch 81.43 | loss 440.58\n",
            "| epoch  88 |  200/ 233 batches | ms/batch 80.21 | loss 436.70\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  88 | time: 25.11s | valid loss 350.23 | n100 0.409 | r20 0.379 | r50 0.518\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  89 |  100/ 233 batches | ms/batch 80.90 | loss 440.17\n",
            "| epoch  89 |  200/ 233 batches | ms/batch 80.68 | loss 432.07\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  89 | time: 25.23s | valid loss 350.08 | n100 0.409 | r20 0.379 | r50 0.518\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  90 |  100/ 233 batches | ms/batch 82.96 | loss 436.61\n",
            "| epoch  90 |  200/ 233 batches | ms/batch 81.56 | loss 434.92\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  90 | time: 25.51s | valid loss 350.26 | n100 0.408 | r20 0.378 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  91 |  100/ 233 batches | ms/batch 81.39 | loss 438.86\n",
            "| epoch  91 |  200/ 233 batches | ms/batch 79.81 | loss 434.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  91 | time: 25.33s | valid loss 349.95 | n100 0.409 | r20 0.378 | r50 0.518\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  92 |  100/ 233 batches | ms/batch 81.76 | loss 444.87\n",
            "| epoch  92 |  200/ 233 batches | ms/batch 79.86 | loss 431.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  92 | time: 25.10s | valid loss 350.10 | n100 0.409 | r20 0.378 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  93 |  100/ 233 batches | ms/batch 82.56 | loss 438.86\n",
            "| epoch  93 |  200/ 233 batches | ms/batch 80.16 | loss 438.24\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  93 | time: 25.38s | valid loss 350.11 | n100 0.409 | r20 0.379 | r50 0.519\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  94 |  100/ 233 batches | ms/batch 84.25 | loss 439.83\n",
            "| epoch  94 |  200/ 233 batches | ms/batch 79.92 | loss 434.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  94 | time: 25.39s | valid loss 350.15 | n100 0.408 | r20 0.378 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  95 |  100/ 233 batches | ms/batch 80.43 | loss 436.06\n",
            "| epoch  95 |  200/ 233 batches | ms/batch 80.02 | loss 437.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  95 | time: 25.30s | valid loss 350.36 | n100 0.409 | r20 0.380 | r50 0.520\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  96 |  100/ 233 batches | ms/batch 81.42 | loss 436.73\n",
            "| epoch  96 |  200/ 233 batches | ms/batch 79.74 | loss 438.99\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  96 | time: 25.08s | valid loss 350.06 | n100 0.409 | r20 0.378 | r50 0.519\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  97 |  100/ 233 batches | ms/batch 80.71 | loss 443.29\n",
            "| epoch  97 |  200/ 233 batches | ms/batch 79.81 | loss 431.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  97 | time: 25.07s | valid loss 350.31 | n100 0.410 | r20 0.379 | r50 0.519\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  98 |  100/ 233 batches | ms/batch 83.73 | loss 439.22\n",
            "| epoch  98 |  200/ 233 batches | ms/batch 80.17 | loss 434.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  98 | time: 25.40s | valid loss 350.06 | n100 0.407 | r20 0.379 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  99 |  100/ 233 batches | ms/batch 81.22 | loss 441.23\n",
            "| epoch  99 |  200/ 233 batches | ms/batch 79.96 | loss 434.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  99 | time: 25.29s | valid loss 350.12 | n100 0.409 | r20 0.379 | r50 0.517\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 100 |  100/ 233 batches | ms/batch 81.68 | loss 434.39\n",
            "| epoch 100 |  200/ 233 batches | ms/batch 80.02 | loss 437.85\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch 100 | time: 25.23s | valid loss 349.99 | n100 0.410 | r20 0.379 | r50 0.520\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss 349.96 | n100 0.41 | r20 0.38 | r50 0.52\n",
            "=========================================================================================\n"
          ]
        }
      ],
      "source": [
        "!python main.py --cuda --anneal_cap 1 --total_anneal_steps 20000 --plots swd-ml20m-epoch100-anneal1 --lr 1e-3 --epochs 100"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "experiments.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}